# SHA1:e82ace487611083e7372bccb3a03991d76043a4b
#
# This file is autogenerated by pip-compile-multi
# To update, run:
#
#    pip-compile-multi
#
aiohttp==3.9.1
    # via
    #   langchain
    #   openai
aiosignal==1.3.1
    # via aiohttp
anyio==3.7.1
    # via
    #   fastapi
    #   langchain-core
    #   starlette
    #   watchfiles
async-timeout==4.0.3
    # via
    #   aiohttp
    #   langchain
attrs==23.1.0
    # via aiohttp
boto3==1.33.11
    # via -r requirements/base.in
botocore==1.33.11
    # via
    #   boto3
    #   s3transfer
certifi==2023.11.17
    # via requests
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via uvicorn
databricks-sql-connector==3.0.1
    # via -r requirements/base.in
dataclasses-json==0.6.3
    # via langchain
et-xmlfile==1.1.0
    # via openpyxl
exceptiongroup==1.2.0
    # via anyio
fastapi==0.104.1
    # via -r requirements/base.in
frozenlist==1.4.0
    # via
    #   aiohttp
    #   aiosignal
greenlet==3.0.2
    # via sqlalchemy
h11==0.14.0
    # via uvicorn
httptools==0.6.1
    # via uvicorn
idna==3.6
    # via
    #   anyio
    #   requests
    #   yarl
jmespath==1.0.1
    # via
    #   boto3
    #   botocore
jsonpatch==1.33
    # via
    #   langchain
    #   langchain-core
jsonpointer==2.4
    # via jsonpatch
langchain==0.0.348
    # via pyspark-ai
langchain-core==0.0.12
    # via langchain
langsmith==0.0.69
    # via
    #   langchain
    #   langchain-core
lz4==4.3.2
    # via databricks-sql-connector
marshmallow==3.20.1
    # via dataclasses-json
multidict==6.0.4
    # via
    #   aiohttp
    #   yarl
mypy-extensions==1.0.0
    # via typing-inspect
numpy==1.24.4
    # via
    #   databricks-sql-connector
    #   langchain
    #   pandas
    #   pyarrow
oauthlib==3.2.2
    # via databricks-sql-connector
openai==0.27.10
    # via
    #   -r requirements/base.in
    #   pyspark-ai
openpyxl==3.1.2
    # via databricks-sql-connector
packaging==23.2
    # via
    #   langchain-core
    #   marshmallow
pandas==2.0.3
    # via
    #   -r requirements/base.in
    #   databricks-sql-connector
pyarrow==14.0.1
    # via
    #   -r requirements/base.in
    #   databricks-sql-connector
pydantic==1.10.13
    # via
    #   fastapi
    #   langchain
    #   langchain-core
    #   langsmith
    #   pyspark-ai
pygments==2.17.2
    # via pyspark-ai
pyspark-ai==0.1.19
    # via -r requirements/base.in
python-dateutil==2.8.2
    # via
    #   botocore
    #   pandas
python-dotenv==1.0.0
    # via uvicorn
pytz==2023.3.post1
    # via pandas
pyyaml==6.0.1
    # via
    #   langchain
    #   langchain-core
    #   uvicorn
requests==2.31.0
    # via
    #   databricks-sql-connector
    #   langchain
    #   langchain-core
    #   langsmith
    #   openai
s3transfer==0.8.2
    # via boto3
six==1.16.0
    # via
    #   python-dateutil
    #   thrift
sniffio==1.3.0
    # via anyio
sqlalchemy==2.0.23
    # via langchain
starlette==0.27.0
    # via fastapi
tenacity==8.2.3
    # via
    #   langchain
    #   langchain-core
thrift==0.16.0
    # via databricks-sql-connector
tqdm==4.66.1
    # via openai
typing-extensions==4.9.0
    # via
    #   fastapi
    #   pydantic
    #   sqlalchemy
    #   starlette
    #   typing-inspect
    #   uvicorn
typing-inspect==0.9.0
    # via dataclasses-json
tzdata==2023.3
    # via pandas
urllib3==1.26.18
    # via
    #   botocore
    #   databricks-sql-connector
    #   requests
uvicorn[standard]==0.24.0.post1
    # via -r requirements/base.in
uvloop==0.19.0
    # via uvicorn
watchfiles==0.21.0
    # via uvicorn
websockets==12.0
    # via uvicorn
yarl==1.9.4
    # via aiohttp
